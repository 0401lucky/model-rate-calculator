/**
 * ä» models.dev è·å–æ¨¡å‹ä»·æ ¼æ•°æ®å¹¶è½¬æ¢ä¸º JSON
 * ç”¨äºæ„å»ºæ—¶é¢„å¤„ç†æ•°æ®
 */

import * as fs from 'fs';
import * as path from 'path';
import * as TOML from '@iarna/toml';

const GITHUB_RAW_BASE = 'https://raw.githubusercontent.com/anomalyco/models.dev/dev';
const GITHUB_API_BASE = 'https://api.github.com/repos/anomalyco/models.dev';

// ä¸»æµæä¾›å•†åˆ—è¡¨ï¼ˆä¼˜å…ˆè·å–è¿™äº›ï¼‰
const PRIORITY_PROVIDERS = [
  'openai',
  'anthropic', 
  'google',
  'deepseek',
  'meta',
  'mistral',
  'cohere',
  'alibaba',
  'moonshot',
  'zhipu',
  'baichuan',
  'minimax',
  'bytedance',
  '01-ai',
  'xai',
  'amazon',
];

interface ModelCost {
  input?: number;
  output?: number;
  cache_read?: number;
  cache_write?: number;
  reasoning?: number;
  input_audio?: number;
  output_audio?: number;
}

interface ModelLimit {
  context?: number;
  output?: number;
}

interface RawModelData {
  name?: string;
  family?: string;
  cost?: ModelCost;
  limit?: ModelLimit;
  modalities?: string[];
}

export interface ModelData {
  id: string;
  name: string;
  provider: string;
  family?: string;
  cost: {
    input: number;
    output: number;
    cacheRead?: number;
    cacheWrite?: number;
    reasoning?: number;
  };
  limits?: {
    context?: number;
    output?: number;
  };
  modalities?: string[];
  // è®¡ç®—åçš„ new-api å€ç‡
  newApiRates: {
    modelRatio: number;
    completionRatio: number;
  };
}

/**
 * è®¡ç®— new-api å€ç‡
 * å…¬å¼ï¼š
 * - æ¨¡å‹å€ç‡ = å®˜æ–¹è¾“å…¥ä»·æ ¼($/1M) Ã— 0.5
 * - è¡¥å…¨å€ç‡ = è¾“å‡ºä»·æ ¼ / è¾“å…¥ä»·æ ¼
 */
function calculateNewApiRates(cost: ModelCost): { modelRatio: number; completionRatio: number } {
  const input = cost.input || 0;
  const output = cost.output || 0;
  
  // æ¨¡å‹å€ç‡ = è¾“å…¥ä»·æ ¼($/1M tokens) Ã— 0.5
  // å› ä¸º 1 ç¾å…ƒ = 500,000 é…é¢ï¼Œæ‰€ä»¥ $1/1M tokens = 0.5 å€ç‡
  const modelRatio = input * 0.5;
  
  // è¡¥å…¨å€ç‡ = è¾“å‡ºä»·æ ¼ / è¾“å…¥ä»·æ ¼
  // å¦‚æœè¾“å…¥ä»·æ ¼ä¸º 0ï¼Œé»˜è®¤è¡¥å…¨å€ç‡ä¸º 1
  const completionRatio = input > 0 ? output / input : 1;
  
  return {
    modelRatio: Math.round(modelRatio * 10000) / 10000,
    completionRatio: Math.round(completionRatio * 10000) / 10000,
  };
}

async function fetchWithRetry(url: string, retries = 3): Promise<Response> {
  for (let i = 0; i < retries; i++) {
    try {
      const response = await fetch(url);
      if (response.ok) return response;
      if (response.status === 404) throw new Error('Not found');
    } catch (error) {
      if (i === retries - 1) throw error;
      await new Promise(r => setTimeout(r, 1000 * (i + 1)));
    }
  }
  throw new Error('Max retries exceeded');
}

async function getProviderModels(provider: string): Promise<string[]> {
  try {
    const url = `${GITHUB_API_BASE}/contents/providers/${provider}/models`;
    const response = await fetchWithRetry(url);
    const files = await response.json() as Array<{ name: string }>;
    return files
      .filter(f => f.name.endsWith('.toml'))
      .map(f => f.name.replace('.toml', ''));
  } catch {
    console.error(`Failed to get models for ${provider}`);
    return [];
  }
}

async function fetchModelData(provider: string, modelId: string): Promise<ModelData | null> {
  try {
    const url = `${GITHUB_RAW_BASE}/providers/${provider}/models/${modelId}.toml`;
    const response = await fetchWithRetry(url);
    const tomlText = await response.text();
    const data = TOML.parse(tomlText) as RawModelData;
    
    if (!data.cost?.input && !data.cost?.output) {
      return null;
    }

    const cost = {
      input: data.cost?.input || 0,
      output: data.cost?.output || 0,
      cacheRead: data.cost?.cache_read,
      cacheWrite: data.cost?.cache_write,
      reasoning: data.cost?.reasoning,
    };

    return {
      id: modelId,
      name: data.name || modelId,
      provider,
      family: data.family,
      cost,
      limits: data.limit ? {
        context: data.limit.context,
        output: data.limit.output,
      } : undefined,
      modalities: data.modalities,
      newApiRates: calculateNewApiRates(data.cost || {}),
    };
  } catch (error) {
    console.error(`Failed to fetch ${provider}/${modelId}:`, error);
    return null;
  }
}

async function main() {
  console.log('ğŸš€ å¼€å§‹è·å–æ¨¡å‹æ•°æ®...');
  
  const allModels: ModelData[] = [];
  
  for (const provider of PRIORITY_PROVIDERS) {
    console.log(`\nğŸ“¦ å¤„ç†æä¾›å•†: ${provider}`);
    const modelIds = await getProviderModels(provider);
    console.log(`   æ‰¾åˆ° ${modelIds.length} ä¸ªæ¨¡å‹`);
    
    // æ‰¹é‡è·å–ï¼Œæ¯æ‰¹ 10 ä¸ª
    for (let i = 0; i < modelIds.length; i += 10) {
      const batch = modelIds.slice(i, i + 10);
      const results = await Promise.all(
        batch.map(id => fetchModelData(provider, id))
      );
      
      results.forEach(model => {
        if (model) allModels.push(model);
      });
      
      // é¿å…è¯·æ±‚è¿‡å¿«
      if (i + 10 < modelIds.length) {
        await new Promise(r => setTimeout(r, 500));
      }
    }
  }

  console.log(`\nâœ… å…±è·å– ${allModels.length} ä¸ªæ¨¡å‹æ•°æ®`);

  // æŒ‰æä¾›å•†åˆ†ç»„
  const byProvider: Record<string, ModelData[]> = {};
  allModels.forEach(model => {
    if (!byProvider[model.provider]) {
      byProvider[model.provider] = [];
    }
    byProvider[model.provider].push(model);
  });

  // å†™å…¥æ–‡ä»¶
  const outputPath = path.join(process.cwd(), 'src/data/models.json');
  fs.mkdirSync(path.dirname(outputPath), { recursive: true });
  fs.writeFileSync(outputPath, JSON.stringify({
    updatedAt: new Date().toISOString(),
    providers: Object.keys(byProvider).sort(),
    models: allModels,
    byProvider,
  }, null, 2));

  console.log(`ğŸ“ æ•°æ®å·²å†™å…¥: ${outputPath}`);
}

main().catch(console.error);
